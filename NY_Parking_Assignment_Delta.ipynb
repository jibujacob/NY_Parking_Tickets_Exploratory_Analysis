{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NY Parking Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below parameters needs to be validated with respective environments\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/opt/cloudera/parcels/Anaconda/bin/python\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_232-cloudera/jre\" \n",
    "os.environ[\"SPARK_HOME\"]=\"/opt/cloudera/parcels/SPARK2-2.3.0.cloudera2-1.cdh5.13.3.p0.316101/lib/spark2/\" \n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.6-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Spark Session and Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-0-212.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.cloudera2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NY_Parking_Assignment</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd50c985110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('NY_Parking_Assignment').master(\"local\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling the data from S3 bucket to local dataframe will bring the default datatypes as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3path = 's3a://upgrad-data/Parking_Violation_Tickets.csv'\n",
    "tickets = spark.read.format(\"csv\").option(\"header\", \"true\").load(s3path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Summons Number: string (nullable = true)\n",
      " |-- Plate ID: string (nullable = true)\n",
      " |-- Registration State: string (nullable = true)\n",
      " |-- Plate Type: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Violation Code: string (nullable = true)\n",
      " |-- Vehicle Body Type: string (nullable = true)\n",
      " |-- Vehicle Make: string (nullable = true)\n",
      " |-- Issuing Agency: string (nullable = true)\n",
      " |-- Street Code1: string (nullable = true)\n",
      " |-- Street Code2: string (nullable = true)\n",
      " |-- Street Code3: string (nullable = true)\n",
      " |-- Vehicle Expiration Date: string (nullable = true)\n",
      " |-- Violation Location: string (nullable = true)\n",
      " |-- Violation Precinct: string (nullable = true)\n",
      " |-- Issuer Precinct: string (nullable = true)\n",
      " |-- Issuer Code: string (nullable = true)\n",
      " |-- Issuer Command: string (nullable = true)\n",
      " |-- Issuer Squad: string (nullable = true)\n",
      " |-- Violation Time: string (nullable = true)\n",
      " |-- Time First Observed: string (nullable = true)\n",
      " |-- Violation County: string (nullable = true)\n",
      " |-- Violation In Front Of Or Opposite: string (nullable = true)\n",
      " |-- House Number: string (nullable = true)\n",
      " |-- Street Name: string (nullable = true)\n",
      " |-- Intersecting Street: string (nullable = true)\n",
      " |-- Date First Observed: string (nullable = true)\n",
      " |-- Law Section: string (nullable = true)\n",
      " |-- Sub Division: string (nullable = true)\n",
      " |-- Violation Legal Code: string (nullable = true)\n",
      " |-- Days Parking In Effect    : string (nullable = true)\n",
      " |-- From Hours In Effect: string (nullable = true)\n",
      " |-- To Hours In Effect: string (nullable = true)\n",
      " |-- Vehicle Color: string (nullable = true)\n",
      " |-- Unregistered Vehicle?: string (nullable = true)\n",
      " |-- Vehicle Year: string (nullable = true)\n",
      " |-- Meter Number: string (nullable = true)\n",
      " |-- Feet From Curb: string (nullable = true)\n",
      " |-- Violation Post Code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- No Standing or Stopping Violation: string (nullable = true)\n",
      " |-- Hydrant Violation: string (nullable = true)\n",
      " |-- Double Parking Violation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tickets.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As shown above the metadata extracted will have the default datatype , and above all columns may not be needed so a new data frame will be created based on the requirement of the analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maintaing oly relevant columns for analysis\n",
    "tickets_with_relevant_columns=tickets.select(\"Summons Number\",\"Plate ID\",\"Registration State\",\"Issue Date\",\n",
    "                                             \"Violation Code\",\"Vehicle Body Type\",\"Vehicle Make\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's keep the datatype in sync with the data for the relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType,IntegerType,StringType;\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "tickets_with_relevant_columns = tickets_with_relevant_columns \\\n",
    ".withColumn(\"Summons Number\",tickets_with_relevant_columns[\"Summons Number\"].cast(LongType())) \\\n",
    ".withColumn(\"Violation Code\",tickets_with_relevant_columns[\"Violation Code\"].cast(IntegerType())) \\\n",
    ".withColumn(\"Issue Date\",unix_timestamp(tickets_with_relevant_columns[\"Issue Date\"],'MM/dd/yyyy').cast('timestamp'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated datatype of the analysis dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Summons Number: long (nullable = true)\n",
      " |-- Plate ID: string (nullable = true)\n",
      " |-- Registration State: string (nullable = true)\n",
      " |-- Issue Date: timestamp (nullable = true)\n",
      " |-- Violation Code: integer (nullable = true)\n",
      " |-- Vehicle Body Type: string (nullable = true)\n",
      " |-- Vehicle Make: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tickets_with_relevant_columns.printSchema()\n",
    "ny_analysis=tickets_with_relevant_columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is executed for performance improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+\n",
      "|    5092469481| GZH7067|                NY|2016-07-10 00:00:00|             7|             SUBN|       TOYOT|\n",
      "|    5092451658| GZH7067|                NY|2016-07-08 00:00:00|             7|             SUBN|       TOYOT|\n",
      "|    4006265037| FZX9232|                NY|2016-08-23 00:00:00|             5|             SUBN|        FORD|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Caching to improve performance for the remainder of the queries as this is the base\n",
    "#When this cell is run the entire notebook takes 6 min and 23 seconds on average to be executed successfully\n",
    "##When this cell is not run the entire notebook takes 23 min and 54 seconds on average to be executed successfully\n",
    "ny_analysis.cache()\n",
    "ny_analysis.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Temporary table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_analysis.registerTempTable(\"ny_parking\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below are the Analysis done for the exploitary Questions\n",
    "## Examine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:Find the total number of tickets for the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10803028"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using dataframes -->Result 10803028\n",
    "ny_analysis.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|   count|\n",
      "+--------+\n",
      "|10803028|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using sparkSQL\n",
    "spark.sql(\"select count(1) as count from ny_parking\").show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1 : The total number of tickets for the year was 10803028 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Find out the number of unique states from where the cars that got parking tickets came. (Hint: Use the column 'Registration  State'.) There is a numeric entry '99' in the column, which should be corrected. Replace it with the state having the maximum entries. Provide the number of unique states again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of unique states from where the cars that got parking tickets came before data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|Total_States_Before_Cleanup|\n",
      "+---------------------------+\n",
      "|                         67|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grouping the dataset based onthe state and counting the distinct values\n",
    "ny_analysis.select(ny_analysis[\"Registration State\"]) \\\n",
    "            .agg(countDistinct(ny_analysis[\"Registration State\"]).alias(\"Total_States_Before_Cleanup\")) \\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution : Before Data Clean up ,the total number of unique states from where the cars that got parking tickets came was 67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below tasks are done to clean the data as per the expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below script is written to find the State with maximum tickets before cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+\n",
      "|Registration State|Tickets Count|\n",
      "+------------------+-------------+\n",
      "|                NY|      8481061|\n",
      "|                NJ|       925965|\n",
      "|                PA|       285419|\n",
      "|                FL|       144556|\n",
      "|                CT|       141088|\n",
      "|                MA|        85547|\n",
      "|                IN|        80749|\n",
      "|                VA|        72626|\n",
      "|                MD|        61800|\n",
      "|                NC|        55806|\n",
      "|                IL|        37329|\n",
      "|                GA|        36852|\n",
      "|                99|        36625|\n",
      "|                TX|        36516|\n",
      "|                AZ|        26426|\n",
      "|                OH|        25302|\n",
      "|                CA|        24260|\n",
      "|                SC|        21836|\n",
      "|                ME|        21574|\n",
      "|                MN|        18227|\n",
      "+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grouping the states based on tickets aquired and sorting it to find state with max tickets \n",
    "\n",
    "ny_analysis.groupby(ny_analysis[\"Registration State\"]) \\\n",
    "            .agg(count(ny_analysis[\"Summons Number\"]).alias(\"Tickets Count\")) \\\n",
    "            .sort(col(\"Tickets Count\"),ascending=False) \\\n",
    "            .show();\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating the datapoint of Registration State of 99 with NY as it has the most number of tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without When and otherwise\n",
    "# ny_analysis_data_updated = ny_analysis.withColumn(\"New Registration State\", \\\n",
    "#                                      regexp_replace(ny_analysis[\"Registration State\"],\"99\",\"NY\"));\n",
    "\n",
    "# With When and otherwise\n",
    "# ny_analysis_data_updated = ny_analysis.withColumn(\"New Registration State\", \\\n",
    "#                                     when(ny_analysis[\"Registration State\"]==\"99\", \\\n",
    "#                                      regexp_replace(ny_analysis[\"Registration State\"],\"99\",\"NY\")) \\\n",
    "#                                     .otherwise(ny_analysis[\"Registration State\"]))\n",
    "\n",
    "\n",
    "#Using below as getting the results a lil faster\n",
    "ny_analysis_data_updated = ny_analysis.withColumn(\"Registration State\", \\\n",
    "                                    when(ny_analysis[\"Registration State\"]==\"99\", \\\n",
    "                                     regexp_replace(ny_analysis[\"Registration State\"],\"99\",\"NY\")) \\\n",
    "                                    .otherwise(ny_analysis[\"Registration State\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The datapoint is updated and now total count of NY cases has increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8517686"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_analysis_data_updated.filter(ny_analysis_data_updated[\"Registration State\"] ==\"NY\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of unique states from where the cars that got parking tickets came after data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|Total_States_After_Cleanup|\n",
      "+--------------------------+\n",
      "|                        66|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ny_analysis_data_updated.select(ny_analysis_data_updated[\"Registration State\"]).agg(countDistinct(ny_analysis_data_updated[\"Registration State\"]).alias(\"Total_States_After_Cleanup\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2: After Data Clean up ,the total number of unique states from where the cars that got parking tickets came was 66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 :Display the top 20 states with the most number of tickets along with their ticket count.(After Cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+\n",
      "|Registration State|Tickets Count|\n",
      "+------------------+-------------+\n",
      "|                NY|      8517686|\n",
      "|                NJ|       925965|\n",
      "|                PA|       285419|\n",
      "|                FL|       144556|\n",
      "|                CT|       141088|\n",
      "|                MA|        85547|\n",
      "|                IN|        80749|\n",
      "|                VA|        72626|\n",
      "|                MD|        61800|\n",
      "|                NC|        55806|\n",
      "|                IL|        37329|\n",
      "|                GA|        36852|\n",
      "|                TX|        36516|\n",
      "|                AZ|        26426|\n",
      "|                OH|        25302|\n",
      "|                CA|        24260|\n",
      "|                SC|        21836|\n",
      "|                ME|        21574|\n",
      "|                MN|        18227|\n",
      "|                OK|        18165|\n",
      "+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Same script as line 69 only running it post data cleanup\n",
    "ny_analysis_data_updated.groupby(ny_analysis_data_updated[\"Registration State\"]) \\\n",
    "            .agg(count(ny_analysis_data_updated[\"Summons Number\"]).alias(\"Tickets Count\")) \\\n",
    "            .sort(col(\"Tickets Count\"),ascending=False) \\\n",
    "            .show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3 : Above is the list of states with most number of tickets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Setting up temporary table \n",
    "ny_analysis_data_updated.registerTempTable(\"ny_parking_updated\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: How often does each violation code occur? Display the frequency of the top five violation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------------+\n",
      "|Violation Code|Frequency_Violation_Code|\n",
      "+--------------+------------------------+\n",
      "|            21|                 1528588|\n",
      "|            36|                 1400614|\n",
      "|            38|                 1062304|\n",
      "|            14|                  893498|\n",
      "|            20|                  618593|\n",
      "+--------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Dataframes : Grouping the violation code based on the number of ticket to get tickets per code\n",
    "ny_analysis_data_updated.groupby(ny_analysis_data_updated[\"Violation Code\"]) \\\n",
    "                    .agg(count(ny_analysis_data_updated[\"Summons Number\"]).alias(\"Frequency_Violation_Code\")) \\\n",
    "                    .sort(col(\"Frequency_Violation_Code\"),ascending=False) \\\n",
    "                    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------------+\n",
      "|Violation Code|Frequency_Violation_Code|\n",
      "+--------------+------------------------+\n",
      "|            21|                 1528588|\n",
      "|            36|                 1400614|\n",
      "|            38|                 1062304|\n",
      "|            14|                  893498|\n",
      "|            20|                  618593|\n",
      "+--------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using sparkSQL : : Grouping the violation code based on the number of ticket to get tickets per code\n",
    "spark.sql(\"select `Violation Code`,count(`Summons Number`) as Frequency_Violation_Code from ny_parking_updated group by `Violation Code` order by count(`Summons Number`) desc \").show(5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1: Above the top 5 violation codes among which code 21 has occured the most number of times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How often does each 'vehicle body type' get a parking ticket? How about the 'vehicle make'? Find the top 5 for both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vehicle Body Type Ticket Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+\n",
      "|Vehicle Body Type|Tickets_Recieved|\n",
      "+-----------------+----------------+\n",
      "|             SUBN|         3719802|\n",
      "|             4DSD|         3082020|\n",
      "|              VAN|         1411970|\n",
      "|             DELV|          687330|\n",
      "|              SDN|          438191|\n",
      "+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Dataframes based on vehicle body type tickets recieved frequency\n",
    "ny_analysis_data_updated.groupby(ny_analysis_data_updated[\"Vehicle Body Type\"]) \\\n",
    "                .agg(count(ny_analysis_data_updated[\"Summons Number\"]).alias(\"Tickets_Recieved\")) \\\n",
    "                .sort(col(\"Tickets_Recieved\"),ascending=False) \\\n",
    "                .show(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+\n",
      "|Vehicle Body Type|Tickets_Recieved|\n",
      "+-----------------+----------------+\n",
      "|             SUBN|         3719802|\n",
      "|             4DSD|         3082020|\n",
      "|              VAN|         1411970|\n",
      "|             DELV|          687330|\n",
      "|              SDN|          438191|\n",
      "+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using SparkSQL based on vehicle body type tickets recieved frequency\n",
    "spark.sql(\"select `Vehicle Body Type`,count(`Summons Number`) as Tickets_Recieved from ny_parking_updated group by `Vehicle Body Type` order by count(`Summons Number`) desc\").show(5);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vehicle Make Ticket Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|Vehicle Make|Tickets_Recieved|\n",
      "+------------+----------------+\n",
      "|        FORD|         1280958|\n",
      "|       TOYOT|         1211451|\n",
      "|       HONDA|         1079238|\n",
      "|       NISSA|          918590|\n",
      "|       CHEVR|          714655|\n",
      "+------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Dataframes based on vehicle make tickets recieved frequency\n",
    "ny_analysis_data_updated.groupby(ny_analysis_data_updated[\"Vehicle Make\"]) \\\n",
    "                .agg(count(ny_analysis_data_updated[\"Summons Number\"]).alias(\"Tickets_Recieved\")) \\\n",
    "                .sort(col(\"Tickets_Recieved\"),ascending=False) \\\n",
    "                .show(5)\n",
    "    \n",
    "# ny_analysis_data_updated.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|Vehicle Make|Tickets_Recieved|\n",
      "+------------+----------------+\n",
      "|        FORD|         1280958|\n",
      "|       TOYOT|         1211451|\n",
      "|       HONDA|         1079238|\n",
      "|       NISSA|          918590|\n",
      "|       CHEVR|          714655|\n",
      "+------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using SparkSQL based on vehicle Make tickets recieved frequency\n",
    "spark.sql(\"select `Vehicle Make`,count(`Summons Number`) as Tickets_Recieved from ny_parking_updated group by `Vehicle Make` order by count(`Summons Number`) desc\").show(5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2 : Above we have both the tickets recieved based on both Vehicle Make and Vehicle body type wherein, the FORD Make has the most number of tickets of 1280958 and the SUBN body type has the most ticket number of 3719802"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### : Question 3 Let’s try and find some seasonality in this data:\n",
    "### Question 3.1: First, divide the year into 4 seasons, and find the frequencies of tickets for each season. (Hints: Use Issue Date to segregate into seasons. You may use a UDF or when-otherwise statement to do so. You have to cast the date format before you can get the month of IssueDate. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions based on the seasons taken from https://www.nyc.com/visitor_guide/weather_facts.75835/\n",
    "#### Fall Season          ->  September, October, November (9,10,11)\n",
    "#### Winter Season     ->  December, January, February (12,1,2)\n",
    "#### Spring Season     ->  March, April, May (3,4,5)\n",
    "#### Summer Season  ->  June, July, August (6,7,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating udf for setting seasons and creating new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating function to return Seasons based on the month passed as input\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def seasons(month):\n",
    "    if month in (9,10,11):\n",
    "        return \"Fall\"\n",
    "    elif month in (12,1,2):\n",
    "        return \"Winter\"\n",
    "    elif month in (3,4,5):\n",
    "        return \"Spring\"\n",
    "    else:\n",
    "        return \"Summer\"\n",
    "        \n",
    "seasons = udf(seasons, StringType())\n",
    "\n",
    "ny_analysis_seasonal=ny_analysis_data_updated.withColumn(\"Seasons\",seasons(month(ny_analysis_data_updated[\"Issue Date\"])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|Seasons|Ticket Frequency|\n",
      "+-------+----------------+\n",
      "| Spring|         2880687|\n",
      "|   Fall|         2830802|\n",
      "| Summer|         2606208|\n",
      "| Winter|         2485331|\n",
      "+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Data frames extracting the frequencies of tickets based on seasons\n",
    "ny_analysis_seasonal.groupby(ny_analysis_seasonal[\"Seasons\"]) \\\n",
    "                    .agg(count(ny_analysis_seasonal[\"Summons Number\"]).alias(\"Ticket Frequency\")) \\\n",
    "                    .sort(col(\"Ticket Frequency\"),ascending=False) \\\n",
    "                    .show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+\n",
      "|Seasons|count(Summons Number)|\n",
      "+-------+---------------------+\n",
      "| Spring|              2880687|\n",
      "|   Fall|              2830802|\n",
      "| Summer|              2606208|\n",
      "| Winter|              2485331|\n",
      "+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using SparkSQL extracting the frequencies of tickets based on seasons\n",
    "\n",
    "spark.sql('select case \\\n",
    "                    when Month in (9,10,11) then \"Fall\" \\\n",
    "                    when Month in (12,1,2) then \"Winter\" \\\n",
    "                    when Month in (3,4,5) then \"Spring\" \\\n",
    "                    else \"Summer\" end as Seasons \\\n",
    "                    ,count(`Summons Number`) \\\n",
    "                from \\\n",
    "              (select `Summons Number`,month(`Issue Date`) as Month \\\n",
    "              from ny_parking_updated) \\\n",
    "          group by Seasons \\\n",
    "          order by count(`Summons Number`) desc') \\\n",
    "         .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3.1 : The Spring season has the most tickets and winter has the least"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2 : Find the three most common violations for each of these seasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------------+----+\n",
      "|Seasons|Violation Code|Ticket Frequency|rank|\n",
      "+-------+--------------+----------------+----+\n",
      "| Spring|            21|          402807|   1|\n",
      "| Spring|            36|          344834|   2|\n",
      "| Spring|            38|          271192|   3|\n",
      "| Summer|            21|          405961|   1|\n",
      "| Summer|            38|          247561|   2|\n",
      "| Summer|            36|          240396|   3|\n",
      "|   Fall|            36|          456046|   1|\n",
      "|   Fall|            21|          357479|   2|\n",
      "|   Fall|            38|          283828|   3|\n",
      "| Winter|            21|          362341|   1|\n",
      "| Winter|            36|          359338|   2|\n",
      "| Winter|            38|          259723|   3|\n",
      "+-------+--------------+----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Dataframes and list the top 3 violations for each seasons\n",
    "from pyspark.sql.window import Window\n",
    "ny_analysis_seasonal.groupby(\"Seasons\",\"Violation Code\") \\\n",
    "                    .agg(count(\"Summons Number\").alias(\"Ticket Frequency\")) \\\n",
    "                    .withColumn(\"rank\",dense_rank().over(Window.partitionBy(\"Seasons\").orderBy(col(\"Ticket Frequency\").desc()))) \\\n",
    "                    .filter(\"rank <=3\") \\\n",
    "                    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------------+----+\n",
      "|Seasons|violation_code|Ticket_frequency|rank|\n",
      "+-------+--------------+----------------+----+\n",
      "| Spring|            21|          402807|   1|\n",
      "| Spring|            36|          344834|   2|\n",
      "| Spring|            38|          271192|   3|\n",
      "| Summer|            21|          405961|   1|\n",
      "| Summer|            38|          247561|   2|\n",
      "| Summer|            36|          240396|   3|\n",
      "|   Fall|            36|          456046|   1|\n",
      "|   Fall|            21|          357479|   2|\n",
      "|   Fall|            38|          283828|   3|\n",
      "| Winter|            21|          362341|   1|\n",
      "| Winter|            36|          359338|   2|\n",
      "| Winter|            38|          259723|   3|\n",
      "+-------+--------------+----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use SparkSQL and list the top 3 violations for each seasons\n",
    "\n",
    "spark.sql(' \\\n",
    "    select * from ( \\\n",
    "        select * ,dense_rank() over (partition by Seasons order by Ticket_Frequency desc) as rank \\\n",
    "        from \\\n",
    "         ( \\\n",
    "            select case \\\n",
    "            when Month in (9,10,11) then \"Fall\" \\\n",
    "            when Month in (12,1,2) then \"Winter\" \\\n",
    "            when Month in (3,4,5) then \"Spring\" \\\n",
    "            else \"Summer\" end as Seasons \\\n",
    "            ,violation_code\\\n",
    "            ,count(tickets) as Ticket_frequency \\\n",
    "              from \\\n",
    "              (select `Summons Number` tickets,`Violation Code` violation_code,month(`Issue Date`) as Month \\\n",
    "                  from ny_parking_updated ) \\\n",
    "            group by Seasons,violation_code \\\n",
    "            order by count(tickets) desc \\\n",
    "           ) \\\n",
    "    ) where rank <=3 \\\n",
    "          ') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3.2 : Violation codes 21,36, 38 are th most occuring violations across the seasons where in violation code 21 is the top most during spring, summer, winter and during fall its violation 36 that tops the chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: The fines collected from all the instances of parking violation constitute a source of revenue for the NYC Police Department. Let’s take an example of estimating this for the three most commonly occurring codes:\n",
    "\n",
    "### Question 4.1 : Find the total occurrences of the three most common violation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|Violation Code|Ticket Frequecy|\n",
      "+--------------+---------------+\n",
      "|            21|        1528588|\n",
      "|            36|        1400614|\n",
      "|            38|        1062304|\n",
      "+--------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use dataframes to fetch total occurrences of the three most common violation codes. \n",
    "ny_analysis_data_updated.groupby(\"Violation Code\") \\\n",
    "                    .agg(count(\"Summons Number\").alias(\"Ticket Frequecy\")) \\\n",
    "                    .sort(col(\"Ticket Frequecy\").desc()) \\\n",
    "                    .show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|Violation Code|Ticket Frequecy|\n",
      "+--------------+---------------+\n",
      "|            21|        1528588|\n",
      "|            36|        1400614|\n",
      "|            38|        1062304|\n",
      "+--------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use sparkSQL to fetch total occurrences of the three most common violation codes. \n",
    "\n",
    "spark.sql(\"select `Violation Code`,count(`Summons Number`) as `Ticket Frequecy` from ny_parking_updated group by `Violation Code` order by count(`Summons Number`) desc\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4.1  : Violation codes 21, 36 and 38 are the top 3 most common violation codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation 4.2:\n",
    "### Then, visit the website:\n",
    "### http://www1.nyc.gov/site/finance/vehicles/services-violation-codes.page\n",
    "### It lists the fines associated with different violation codes. They’re divided into two categories: one for the highest-density locations in the city and the other for the rest of the city. For the sake of simplicity, take the average of the two.\n",
    "\n",
    "### Question 4.3 : Using this information, find the total amount collected for each of the three violation codes with the maximum tickets. State the code that has the highest total collection (only based on the top 3 tickets). (Hint: It may be a wise idea to store the fines in a separate column, based on the violation code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilization based on 4.2 expectation\n",
    "#### Violation Code Fines based on above question\n",
    "#### Violation Code 21 -> 65 dollars\n",
    "#### Violation Code 36 -> 50 dollars\n",
    "#### Violation Code 38 -> 50 dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|sum(Fine_Amount)|\n",
      "+----------------+\n",
      "|       222504120|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ny_analysis_fine_df=ny_analysis_data_updated.groupby(\"Violation Code\") \\\n",
    "                    .agg(count(\"Summons Number\").alias(\"Ticket Frequecy\")) \\\n",
    "                    .withColumn(\"Fine\",when(ny_analysis_data_updated[\"Violation Code\"]==21 ,65) \\\n",
    "                                        .when(ny_analysis_data_updated[\"Violation Code\"]==36 ,50) \\\n",
    "                                        .when(ny_analysis_data_updated[\"Violation Code\"]==38 ,50)) \\\n",
    "                    .withColumn(\"Fine_Amount\",col(\"Ticket Frequecy\")*col(\"Fine\")) \\\n",
    "                    .sort(col(\"Ticket Frequecy\").desc()).limit(3)\n",
    "\n",
    "ny_analysis_fine_df.agg(sum(\"Fine_Amount\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4.3 :  Total amount collected was 222504120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.4: Find the top 3 states that have the highest ticket revenue based on the top 3 violation codes alone. (Hint: Use the column 'Registration State'.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+\n",
      "|Registration State|Total_fine|\n",
      "+------------------+----------+\n",
      "|                NY| 177078880|\n",
      "|                NJ|  14753770|\n",
      "|                PA|   6944560|\n",
      "+------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ny_analysis_fineamount_statewise = ny_analysis_data_updated.filter((ny_analysis_data_updated[\"Violation Code\"]==21) | \\\n",
    "                                (ny_analysis_data_updated[\"Violation Code\"]==36) | \\\n",
    "                                (ny_analysis_data_updated[\"Violation Code\"]==38)) \\\n",
    "                    .groupby(\"Registration State\",\"Violation Code\") \\\n",
    "                    .agg(count(\"Summons Number\").alias(\"Ticket Frequecy\")) \\\n",
    "                    .withColumn(\"Fine\",when(ny_analysis_data_updated[\"Violation Code\"]==21 ,65) \\\n",
    "                                        .when(ny_analysis_data_updated[\"Violation Code\"]==36 ,50) \\\n",
    "                                        .when(ny_analysis_data_updated[\"Violation Code\"]==38 ,50)) \\\n",
    "                    .withColumn(\"Fine_Amount\",col(\"Ticket Frequecy\")*col(\"Fine\"))\n",
    "\n",
    "ny_analysis_fineamount_statewise.groupby(\"Registration State\").agg(sum(\"Fine_Amount\").alias(\"Total_fine\")) \\\n",
    "                                .sort(col(\"Total_fine\").desc()).show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4.4: NY , NJ and PA pay the most fines when considering only violations of 21, 36 and 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations (Question 4.5)\n",
    "\n",
    "#### 1.No Parking, Over speeding or Exceeding Parking Time Limit was the violation that occured most frequently \n",
    "#### 2.Total occurence of the violations based on the Seasons did not vary much\n",
    "#### 3.Revenue collected in NY is way greater on a cumulative scale compared to the other states, actions needed to be taken here to mitigate this \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
